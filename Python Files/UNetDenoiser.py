# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wPlYRbOPKBsDsm-7DlFqnT49_-kb-Q2Z
"""

# =============================
# ‚úÖ 1. Mount Google Drive
# =============================
from google.colab import drive
drive.mount('/content/drive')

# =============================
# ‚úÖ 2. Imports
# =============================
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from tqdm import tqdm
import random

# =============================
# ‚úÖ 3. Use GPU if available
# =============================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

import torch
import torch.nn as nn

class UNetBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(UNetBlock, self).__init__()
        self.block = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
        )

    def forward(self, x):
        return self.block(x)

class UNetDenoiser(nn.Module):
    def __init__(self, in_channels=3):
        super(UNetDenoiser, self).__init__()
        self.enc1 = UNetBlock(in_channels, 64)
        self.pool1 = nn.MaxPool2d(2)
        self.enc2 = UNetBlock(64, 128)
        self.pool2 = nn.MaxPool2d(2)

        self.bottleneck = UNetBlock(128, 256)

        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)
        self.dec2 = UNetBlock(256, 128)
        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)
        self.dec1 = UNetBlock(128, 64)

        self.final = nn.Conv2d(64, in_channels, 1)

    def forward(self, x):
        e1 = self.enc1(x)
        e2 = self.enc2(self.pool1(e1))
        b = self.bottleneck(self.pool2(e2))
        d2 = self.dec2(torch.cat([self.up2(b), e2], dim=1))
        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))
        return self.final(d1)

# =============================
# ‚úÖ 5. Dataset Definition
# =============================
class MultiNoiseDenoisingDataset(Dataset):
    def __init__(self, clean_dir, noise_dirs, transform=None):
        self.clean_dir = clean_dir
        self.noise_dirs = noise_dirs
        self.transform = transform

        self.clean_images = sorted([f for f in os.listdir(clean_dir) if f.endswith(('.jpg', '.png'))])
        self.noisy_image_paths = []

        for noise_dir in noise_dirs:
            for img_name in self.clean_images:
                noisy_path = os.path.join(noise_dir, img_name)
                clean_path = os.path.join(clean_dir, img_name)
                if os.path.exists(noisy_path) and os.path.exists(clean_path):
                    self.noisy_image_paths.append((noisy_path, clean_path))

        random.shuffle(self.noisy_image_paths)

    def __len__(self):
        return len(self.noisy_image_paths)

    def __getitem__(self, idx):
        noisy_path, clean_path = self.noisy_image_paths[idx]

        noisy_img = Image.open(noisy_path).convert('RGB')
        clean_img = Image.open(clean_path).convert('RGB')

        if self.transform:
            noisy_img = self.transform(noisy_img)
            clean_img = self.transform(clean_img)

        return noisy_img, clean_img

# =============================
# ‚úÖ 6. Setup Paths
# =============================
base_path = "/content/drive/MyDrive/Colob"
clean_dir = os.path.join(base_path, "clean")
noise_dirs = [
    #os.path.join(base_path, "gaussian_noise")
     os.path.join(base_path, "salt_pepper_noise")
    #os.path.join(base_path, "poisson_noise")
]

# =============================
# ‚úÖ 7. Transform and DataLoader
# =============================
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

dataset = MultiNoiseDenoisingDataset(clean_dir, noise_dirs, transform=transform)
train_loader = DataLoader(dataset, batch_size=8, shuffle=True)

model = UNetDenoiser().to(device)  # Instantiate and move to GPU (or CPU if device='cpu')

# =============================
# ‚úÖ 3. Loss, Optimizer, Scheduler
# =============================
criterion = nn.L1Loss()  # üî• L1 Loss is robust for salt-and-pepper
optimizer = optim.Adam(model.parameters(), lr=1e-3)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)

import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import os
import matplotlib.pyplot as plt
import glob

# =============================
# ‚úÖ 4. Training Loop
# =============================
num_epochs = 100
patience = 15
best_loss = float('inf')
counter = 0
train_losses = []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for noisy_imgs, clean_imgs in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}"):
        noisy_imgs = noisy_imgs.to(device)
        clean_imgs = clean_imgs.to(device)

        outputs = model(noisy_imgs)
        loss = criterion(outputs, clean_imgs)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    avg_loss = running_loss / len(train_loader)
    train_losses.append(avg_loss)

    print(f"‚úÖ Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}")

    scheduler.step(avg_loss)

    # ‚úÖ Save best model
    if avg_loss < best_loss:
        best_loss = avg_loss
        counter = 0
        torch.save(model.state_dict(), "best_model.pth")
        print("üéØ Best model saved.")
    else:
        counter += 1
        print(f"No improvement for {counter} epochs.")
        if counter >= patience:
            print("‚õî Early stopping triggered!")
            break

# # =============================
# # ‚úÖ 5. Save Final Model
# # =============================
# torch.save(model.state_dict(), "final_model.pth")
# print("‚úÖ Final model saved.")

# # =============================
# # ‚úÖ 6. Cleanup (keep only best)
# # =============================
# for ckpt in glob.glob("*.pth"):
#     if ckpt != "best_model.pth":
#         os.remove(ckpt)
#         print(f"üßπ Removed: {ckpt}")



# =============================
# ‚úÖ 5. Save Final Model
# =============================
final_model_path = os.path.join(base_path, "final_model.pth")
torch.save(model.state_dict(), final_model_path)
print(f"‚úÖ Final model saved to {final_model_path}")

# =============================
# ‚úÖ 6. Cleanup (keep only best)
# =============================
best_model_path = os.path.join(base_path, "best_model.pth")

# Only keep best_model.pth in drive directory
for ckpt in glob.glob(os.path.join(base_path, "*.pth")):
    if not ckpt.endswith("best_model.pth"):
        os.remove(ckpt)
        print(f"üßπ Removed: {ckpt}")

# =============================
# ‚úÖ 7. Plot Training Loss
# =============================
plt.figure(figsize=(8,6))
plt.plot(train_losses, marker='o', label='Training Loss')
plt.title('Training Loss Curve')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid()
plt.legend()
plt.show()

checkpoint_path = "/content/drive/MyDrive/Colob/best_model (1).pth"
model.load_state_dict(torch.load(checkpoint_path, map_location=torch.device('cpu')))
model.eval()
print("‚úÖ Pretrained weights loaded successfully!")

from google.colab import files
from PIL import Image
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
# ============================================
# ‚úÖ 3. Image Preprocessing
# ============================================
# Resize and normalize image to tensor
transform = transforms.Compose([
    transforms.Resize((512, 512)),  # Match training size
    transforms.ToTensor()
])

# Load a noisy image
image_path = "/content/0855.png"  # üîÅ update to your test image
noisy_img = Image.open(image_path).convert("RGB")
input_tensor = transform(noisy_img).unsqueeze(0).to(device)

with torch.no_grad():
    denoised = model(input_tensor)

# Remove batch dimension and convert to image
to_pil = transforms.ToPILImage()
denoised_image = to_pil(denoised.squeeze(0))

# Plot side-by-side
plt.figure(figsize=(10,5))
plt.subplot(1,2,1)
plt.title("Original")
plt.imshow(noisy_img)
plt.axis('off')

plt.subplot(1,2,2)
plt.title("Denoised")
plt.imshow(denoised_image)
plt.axis('off')
plt.show()

# output_path = "/content/drive/MyDrive/Colob/denoised_output1.png"
# denoised_image.save(output_path)
# print(f"‚úÖ Denoised image saved at: {output_path}")