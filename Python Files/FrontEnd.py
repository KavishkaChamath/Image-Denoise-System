# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UCjNRQU7rutVwDUzXNEQR_DzhFVTbL5K
"""

!pip install flask-ngrok
!pip install torchvision

# =============================
# âœ… 1. Mount Google Drive
# =============================
from google.colab import drive
drive.mount('/content/drive')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# =============================
# âœ… 4. DnCNN Model Definition
# =============================
class DnCNN(nn.Module):
    def __init__(self, channels=3, num_of_layers=17):
        super(DnCNN, self).__init__()
        kernel_size = 3
        padding = 1
        features = 64
        layers = []
        layers.append(nn.Conv2d(channels, features, kernel_size, padding=padding, bias=False))
        layers.append(nn.ReLU(inplace=True))

        for _ in range(num_of_layers - 2):
            layers.append(nn.Conv2d(features, features, kernel_size, padding=padding, bias=False))
            layers.append(nn.BatchNorm2d(features))
            layers.append(nn.ReLU(inplace=True))

        layers.append(nn.Conv2d(features, channels, kernel_size, padding=padding, bias=False))
        self.dncnn = nn.Sequential(*layers)

    def forward(self, x):
        out = self.dncnn(x)
        return x - out  # Residual learning

import torch
import torch.nn as nn

class ImprovedDnCNN(nn.Module):
    def __init__(self, channels=3, num_of_layers=22):
        super(ImprovedDnCNN, self).__init__()
        kernel_size = 3
        padding = 1
        features = 96
        dropout_prob = 0.2

        layers = []
        layers.append(nn.Conv2d(channels, features, kernel_size, padding=padding, bias=False))
        layers.append(nn.ReLU(inplace=True))

        for _ in range(num_of_layers - 2):
            layers.append(nn.Conv2d(features, features, kernel_size, padding=padding, bias=False))
            layers.append(nn.BatchNorm2d(features))
            layers.append(nn.ReLU(inplace=True))
            layers.append(nn.Dropout(dropout_prob))

        layers.append(nn.Conv2d(features, channels, kernel_size, padding=padding, bias=False))
        self.dncnn = nn.Sequential(*layers)

    def forward(self, x):
        out = self.dncnn(x)
        return x - out

# # Load model
# model = ImprovedDnCNN()
# model.load_state_dict(torch.load('/content/drive/MyDrive/Colob/best_model (1).pth', map_location='cpu'))
# print("âœ… Pretrained weights loaded successfully!")
# model.eval()

import torch
import torch.nn as nn

class UNetBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(UNetBlock, self).__init__()
        self.block = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
        )

    def forward(self, x):
        return self.block(x)

class UNetDenoiser(nn.Module):
    def __init__(self, in_channels=3):
        super(UNetDenoiser, self).__init__()
        self.enc1 = UNetBlock(in_channels, 64)
        self.pool1 = nn.MaxPool2d(2)
        self.enc2 = UNetBlock(64, 128)
        self.pool2 = nn.MaxPool2d(2)

        self.bottleneck = UNetBlock(128, 256)

        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)
        self.dec2 = UNetBlock(256, 128)
        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)
        self.dec1 = UNetBlock(128, 64)

        self.final = nn.Conv2d(64, in_channels, 1)

    def forward(self, x):
        e1 = self.enc1(x)
        e2 = self.enc2(self.pool1(e1))
        b = self.bottleneck(self.pool2(e2))
        d2 = self.dec2(torch.cat([self.up2(b), e2], dim=1))
        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))
        return self.final(d1)

!pip install flask flask-ngrok pyngrok

# Load all models
model_gaussian = ImprovedDnCNN().to(device)
model_gaussian.load_state_dict(torch.load("/content/drive/MyDrive/Colob/Copy of Copy of best_dncnnnew2.pth", map_location=device))
#model_gaussian.eval()

model_poisson = DnCNN().to(device)
model_poisson.load_state_dict(torch.load("/content/drive/MyDrive/Colob/Copy of best_dncnn (2).pth", map_location=device))
#model_poisson.eval()

model_saltpepper = UNetDenoiser().to(device)
model_saltpepper.load_state_dict(torch.load("/content/drive/MyDrive/Colob/best_model (1).pth", map_location=device))
#model_saltpepper.eval()

from flask import Flask, request, send_file
from flask_ngrok import run_with_ngrok
import io
from PIL import Image
import torch
import torchvision.transforms as transforms
#from model import ImprovedDnCNN  # assuming you've defined this earlier
import torch
import torch.nn as nn


class ImprovedDnCNN(nn.Module):
    def __init__(self, channels=3, num_of_layers=22):
        super(ImprovedDnCNN, self).__init__()
        kernel_size = 3
        padding = 1
        features = 96
        dropout_prob = 0.2

        layers = []
        layers.append(nn.Conv2d(channels, features, kernel_size, padding=padding, bias=False))
        layers.append(nn.ReLU(inplace=True))

        for _ in range(num_of_layers - 2):
            layers.append(nn.Conv2d(features, features, kernel_size, padding=padding, bias=False))
            layers.append(nn.BatchNorm2d(features))
            layers.append(nn.ReLU(inplace=True))
            layers.append(nn.Dropout(dropout_prob))

        layers.append(nn.Conv2d(features, channels, kernel_size, padding=padding, bias=False))
        self.dncnn = nn.Sequential(*layers)

    def forward(self, x):
        out = self.dncnn(x)
        return x - out

# Load model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = ImprovedDnCNN().to(device)
checkpoint_path = "/content/drive/MyDrive/Colob/best_dncnnnew2.pth"
model.load_state_dict(torch.load(checkpoint_path, map_location=device))
model.eval()


app = Flask(__name__)
run_with_ngrok(app)  # <-- ðŸ”¥ This starts ngrok in Colab

# Denoise endpoint
@app.route("/denoise", methods=["POST"])
def denoise():
    file = request.files["image"]
    image = Image.open(file.stream).convert("RGB")

    transform = transforms.ToTensor()
    input_tensor = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        output_tensor = model(input_tensor)

    output_image = transforms.ToPILImage()(output_tensor.squeeze(0).cpu())
    buffer = io.BytesIO()
    output_image.save(buffer, format="PNG")
    buffer.seek(0)
    return send_file(buffer, mimetype='image/png')

# Start server
app.run()

from pyngrok import conf, ngrok

# Add your token here
conf.get_default().auth_token = ""

# Start the tunnel
public_url = ngrok.connect(5000)
print(f"ðŸš€ Public URL: {public_url}")

from flask import Flask, request, send_file, render_template, url_for
from pyngrok import ngrok
import io
from PIL import Image
import torch
import torchvision.transforms as transforms
import torch.nn as nn
import os

# Flask app setup
app = Flask(__name__, template_folder="templates", static_folder="static")
os.makedirs("static", exist_ok=True)  # Ensure static folder exists

@app.route("/", methods=["GET"])
def home():
    return render_template("index.html")


@app.route("/denoise", methods=["POST"])
def denoise():
    file = request.files["image"]
    noise_type = request.form["noise_type"]  # Get noise type
    image = Image.open(file.stream).convert("RGB")

    # Save original image
    original_path = os.path.join("static", "original.png")
    image.save(original_path)

    # Denoising
    transform = transforms.ToTensor()
    input_tensor = transform(image).unsqueeze(0).to(device)

    # Select model
    if noise_type == "gaussian":
        selected_model = model_gaussian
    elif noise_type == "poisson":
        selected_model = model_poisson
    elif noise_type == "saltpepper":
        selected_model = model_saltpepper
    else:
        return "Invalid noise type", 400

    with torch.no_grad():
        output_tensor = selected_model(input_tensor)

    output_image = transforms.ToPILImage()(output_tensor.squeeze(0).cpu())

    # Save denoised image
    denoised_path = os.path.join("static", "denoised.png")
    output_image.save(denoised_path)

    return render_template(
        "index.html",
        original_image_url=url_for("static", filename="original.png"),
        denoised_image_url=url_for("static", filename="denoised.png")
    )


# Expose via ngrok
public_url = ngrok.connect(5000)
print(f"ðŸš€ Public URL: {public_url}")

# Start Flask server
app.run()

import os

# Create templates folder
os.makedirs("templates", exist_ok=True)

# Save HTML file
html_code = """
<!doctype html>
<html>
<head>
  <title>Image Denoising</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background: linear-gradient(to right, #d3cce3, #e9e4f0);
      margin: 0;
      padding: 30px;
      color: #333;
    }

    h1 {
      text-align: center;
      color: #4b0082;
    }

    form {
      display: flex;
      flex-direction: column;
      align-items: center;
      margin-bottom: 30px;
    }

    input[type="file"] {
      padding: 10px;
      margin-bottom: 15px;
      border: 2px dashed #4b0082;
      background-color: #f7f3ff;
      cursor: pointer;
    }

    button {
      background-color: #4b0082;
      color: white;
      border: none;
      padding: 10px 20px;
      font-size: 16px;
      border-radius: 8px;
      cursor: pointer;
      transition: background-color 0.3s ease;
    }

    button:hover {
      background-color: #6a0dad;
    }

    .container, .container1 {
      display: flex;
      justify-content: center;
      gap: 40px;
      margin-top: 30px;
      flex-wrap: wrap;
    }

    .image-card {
      background-color: #fff;
      padding: 20px;
      border-radius: 12px;
      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
      text-align: center;
    }

    img {
      max-width: 300px;
      margin-top: 10px;
      border-radius: 10px;
      box-shadow: 0 2px 6px rgba(0, 0, 0, 0.1);
    }

    .spinner {
      border: 6px solid #f3f3f3;
      border-top: 6px solid #4b0082;
      border-radius: 50%;
      width: 40px;
      height: 40px;
      margin: 0 auto;
      animation: spin 1s linear infinite;
    }

    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }

    .label-style {
        color: black;
        font-size: 16px;
        font-weight: bold;
        color: #ffffff;
        margin-bottom: 8px;
        display: block;
      }

      .select-style {
        padding: 10px 15px;
        border-radius: 8px;
        border: 1px solid #ccc;
        background-color: #2c3e50;
        color: white;
        font-size: 14px;
        appearance: none;
        -webkit-appearance: none;
        -moz-appearance: none;
        background-image: url("data:image/svg+xml;utf8,<svg fill='white' height='24' viewBox='0 0 24 24' width='24' xmlns='http://www.w3.org/2000/svg'><path d='M7 10l5 5 5-5z'/></svg>");
        background-repeat: no-repeat;
        background-position: right 10px center;
        background-size: 16px 16px;
        cursor: pointer;
        margin-bottom: 15px;
      }

      .select-style:focus {
        outline: none;
        border-color: #3498db;
        box-shadow: 0 0 5px #3498db;
      }

      .download-button {
      display: inline-block;
      margin-top: 10px;
      padding: 10px 20px;
      background-color: #4b0082;
      color: white;
      text-decoration: none;
      border-radius: 8px;
      transition: background-color 0.3s ease;
    }

    .download-button:hover {
      background-color: #6a0dad;
    }

  </style>
</head>
<body>
  <h1>Image Denoising</h1>
  <form method="post" enctype="multipart/form-data" action="/denoise" onsubmit="clearPreviousResults()">
  <label for="noiseType" class="label-style">Select Noise Type:</label>
  <select name="noise_type" id="noiseType" class="select-style" required>
    <option value="gaussian">Gaussian</option>
    <option value="poisson">Poisson</option>
    <option value="saltpepper">Salt & Pepper</option>
  </select>

    <input type="file" name="image" id="imageInput" required onchange="previewImage(event)">
    <button type="submit">Denoise</button>
  </form>

  <!-- Preview image -->
  <div class="container1" id="previewWrapper" style="display: none;">
    <div class="image-card">
      <h3>Original Image</h3>
      <img id="originalPreview" src="#" alt="Original Preview">
    </div>
  </div>

  <!-- Results after denoising -->
  {% if original_image_url and denoised_image_url %}
  <div class="container" id="resultContainer">
    <div class="image-card">
      <h3>Original Image</h3>
      <img src="{{ original_image_url }}" alt="Original Image">
    </div>
    <div class="image-card">
      <h3>Denoised Image</h3>
      <img src="{{ denoised_image_url }}" alt="Denoised Image">
      <br><br>
    <!-- Download button -->
    <a href="{{ denoised_image_url }}" download="denoised_image.png" class="download-button">Download Denoised Image</a>
    </div>
  </div>
  {% endif %}

  <!-- Loading message or spinner -->
<div id="loading" style="display: none; text-align: center; margin-top: 20px;">
  <p style="font-size: 18px; color: #4b0082;">Denoising image, please wait...</p>
  <div class="spinner"></div>
</div>

  <script>
    function previewImage(event) {
      const reader = new FileReader();
      reader.onload = function () {
        const img = document.getElementById('originalPreview');
        const wrapper = document.getElementById('previewWrapper');
        img.src = reader.result;
        wrapper.style.display = 'flex';
      };
      reader.readAsDataURL(event.target.files[0]);
    }

    function clearPreviousResults() {
      const resultContainer = document.getElementById('resultContainer');
      if (resultContainer) {
        resultContainer.innerHTML = '';
      }
      document.getElementById('loading').style.display = 'block';
    }
  </script>
</body>
</html>

"""
with open("templates/index.html", "w") as f:
    f.write(html_code)